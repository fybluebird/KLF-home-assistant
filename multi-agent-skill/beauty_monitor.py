#!/usr/bin/env python3
"""
ç¾å¦†è¶‹åŠ¿ç›‘æ§ç³»ç»Ÿ V5 - é›†æˆå¯æŠ“å–çš„ç½‘ç«™
"""

import subprocess
import re
from datetime import datetime
from pathlib import Path

SKILL_DIR = Path(__file__).parent
QQ_SEND = "node /home/admin/openclaw/workspace/multi-agent-skill/send_qq.js"
TARGET_OPENID = "352983D4C8F36D56E350266944DF8DE1"

def send_qq(message):
    msg_escaped = message.replace("\n", "\\n")
    subprocess.run(f"{QQ_SEND} {TARGET_OPENID} \"{msg_escaped}\"", shell=True)

def fetch_url(url):
    import urllib.request
    try:
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        response = urllib.request.urlopen(req, timeout=10)
        return response.read().decode('utf-8')
    except:
        return ""

def get_baidu_trends():
    """ç™¾åº¦çƒ­æœ"""
    trends = []
    html = fetch_url("https://top.baidu.com/board?tab=realtime")
    if html:
        items = re.findall(r'title="([^"]+)"', html)[:10]
        if items:
            trends.append("\nğŸ‡¨ğŸ‡³ ç™¾åº¦çƒ­æœ Top10ï¼š")
            for i, item in enumerate(items[:10], 1):
                trends.append(f"  {i}. {item[:30]}")
    return trends

def get_weibo_tech():
    """ç§‘æŠ€å¾®åšçƒ­æœ"""
    trends = []
    html = fetch_url("https://s.weibo.com/top/summary?cate=tech")
    if html and "çƒ­æœ" in html:
        items = re.findall(r'å¾®åšçƒ­æœæ¦œ([^<]+)', html)
        if items:
            trends.append("\nğŸ‡¨ğŸ‡³ å¾®åšç§‘æŠ€çƒ­æœï¼š")
            for i, item in enumerate(items[:5], 1):
                trends.append(f"  {i}. {item[:30]}")
    return trends

def get_douyin_rank():
    """æŠ–éŸ³çƒ­æ¦œ"""
    trends = []
    html = fetch_url("https://www.douyin.com/aweme/v1/web/hot/search/list/")
    if html:
        try:
            import json
            data = json.loads(html)
            if data.get("data") and data["data"].get("word_list"):
                trends.append("\nğŸµ æŠ–éŸ³çƒ­æ¦œï¼š")
                for i, item in enumerate(data["data"]["word_list"][:5], 1):
                    trends.append(f"  {i}. {item.get('word', '')[:30]}")
        except:
            pass
    return trends

def get_glossy():
    """Glossyç¾å¦†"""
    trends = []
    html = fetch_url("https://www.glossy.co/beauty")
    if html:
        titles = re.findall(r'\[([^\]]+)\]\(https?://[^\)]+\)', html)
        if titles:
            trends.append("\nğŸ“° Glossyçƒ­é—¨ï¼š")
            for t in titles[:5]:
                trends.append(f"  â€¢ {t[:50]}")
    return trends

def get_wwd():
    """WWD"""
    trends = []
    html = fetch_url("https://wwd.com/beauty-industry")
    if html:
        titles = re.findall(r'<a[^>]*title="([^"]+)"', html)[:5]
        if titles:
            trends.append("\nğŸ“° WWD Beautyï¼š")
            for t in titles:
                trends.append(f"  â€¢ {t[:50]}")
    return trends

def generate_report():
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    
    report = f"""ğŸ’„ ç¾å¦†è¶‹åŠ¿å‘¨æŠ¥ V5 - {now}
{'='*35}

ã€ğŸ‡ºğŸ‡¸ ç¾å›½æ•°æ®æºã€‘
"""
    report += "\n".join(get_glossy())
    report += "\n".join(get_wwd())
    
    report += """

ã€ğŸ‡¨ğŸ‡³ ä¸­å›½æ•°æ®æºã€‘
"""
    report += "\n".join(get_baidu_trends())
    report += "\n".join(get_douyin_rank())
    
    report += f"""

{'='*35}
ğŸ“Œ å·²æµ‹è¯•å¯ç”¨æ•°æ®æºï¼š
âœ… ç™¾åº¦çƒ­æœ
âœ… Glossy
âœ… WWD
âš ï¸ å¾®åš/æŠ–éŸ³ï¼ˆéœ€APIæˆ–ä»£ç†ï¼‰
"""
    return report

def main():
    print("ğŸ’„ æ­£åœ¨è·å–è¶‹åŠ¿æ•°æ®...")
    report = generate_report()
    print(report)
    send_qq(report)
    print("âœ… æŠ¥å‘Šå·²å‘é€")

if __name__ == "__main__":
    main()
